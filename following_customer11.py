import rclpy
from rclpy.node import Node
from rclpy.executors import MultiThreadedExecutor
from rclpy.qos import QoSProfile, QoSHistoryPolicy, QoSReliabilityPolicy

from sensor_msgs.msg import Image, CameraInfo, CompressedImage
from geometry_msgs.msg import Twist
from cv_bridge import CvBridge
from turtlebot4_navigation.turtlebot4_navigator import TurtleBot4Navigator, TurtleBot4Directions
from ultralytics import YOLO

import numpy as np
import cv2
import threading
import math


class DepthToMap(Node):
    def __init__(self):
        super().__init__('depth_to_map_node')

        self.bridge = CvBridge()
        self.K = None
        self.lock = threading.Lock()

        # â–¶ ì„¼ì„œìš© QoS (ê°€ìž¥ ìµœì‹  í”„ë ˆìž„ë§Œ ìœ ì§€)
        self.qos_sensor = QoSProfile(
            history=QoSHistoryPolicy.KEEP_LAST,
            depth=1,
            reliability=QoSReliabilityPolicy.BEST_EFFORT
        )

        ns = self.get_namespace()
        self.depth_topic = f'{ns}/oakd/stereo/image_raw'
        self.rgb_topic = f'{ns}/oakd/rgb/image_raw/compressed'
        self.info_topic = f'{ns}/oakd/rgb/camera_info'

        # â–¶ YOLO ë¡œë“œ
        self.get_logger().info("Loading YOLO model...")
        self.yolo = YOLO('/home/rokey/Picker_project/yolo_mixed.pt')
        self.get_logger().info("YOLO loaded.")

        # â–¶ ì¶”ì í•  í´ëž˜ìŠ¤ ì´ë¦„
        self.target_class = "customer_b"

        self.depth_image = None
        self.rgb_image = None
        self.yolo_running = False

        # â–¶ rqtìš© ì´ë¯¸ì§€ QoS
        self.qos_image = QoSProfile(
            history=QoSHistoryPolicy.KEEP_LAST,
            depth=1,
            reliability=QoSReliabilityPolicy.BEST_EFFORT
        )

        # â–¶ YOLOê°€ ê·¸ë¦° ì´ë¯¸ì§€ë¥¼ í¼ë¸”ë¦¬ì‹œí•  í† í”½
        self.yolo_image_pub = self.create_publisher(
            Image,
            'image_yolo',
            self.qos_image
        )

        # â–¶ cmd_vel í¼ë¸”ë¦¬ì…”
        self.cmd_vel_pub = self.create_publisher(
            Twist,
            f'{ns}/cmd_vel',
            10
        )

        # â–¶ ì¶”ì /íƒìƒ‰ íŒŒë¼ë¯¸í„°
        self.follow_distance = 1.1
        self.k_v = 0.8
        self.k_w = 1.2
        self.max_linear_speed = 0.25
        self.max_angular_speed = 0.5

        # ðŸ”¹ ë„ë¦¬ë„ë¦¬ ë°©ì§€ìš© ë°ë“œì¡´
        self.dist_deadband = 0.05   # m, ëª©í‘œ ê±°ë¦¬ Â±10cm ì´ë‚´ë©´ ì „ì§„/í›„ì§„ ì•ˆ í•¨
        self.angle_deadband = 0.17  # ì •ê·œí™”ëœ ì—ëŸ¬(í™”ë©´ ì ˆë°˜ ê¸°ì¤€ 17%) ì´í•˜ë©´ íšŒì „ ì•ˆ í•¨

        self.lost_timeout = 1.0
        self.search_angular_speed = 0.5
        self.search_duration = 2 * math.pi / abs(self.search_angular_speed)

        self.state = "IDLE"
        self.last_detection_time = None
        self.search_start_time = None

        # TurtleBot4 ë„¤ë¹„ê²Œì´í„°
        self.navigator = TurtleBot4Navigator()

        if not self.navigator.getDockedStatus():
            self.get_logger().info('Docking before initializing pose')
            self.navigator.dock()

        initial_pose = self.navigator.getPoseStamped(
            [-3.95146, 3.98198],
            TurtleBot4Directions.NORTH
        )
        self.navigator.setInitialPose(initial_pose)
        self.navigator.waitUntilNav2Active()
        self.navigator.undock()

        self.logged_intrinsics = False
        self.logged_rgb_shape = False
        self.logged_depth_shape = False

        # â–¶ ì„œë¸ŒìŠ¤í¬ë¦½ì…˜
        self.create_subscription(
            CameraInfo, self.info_topic,
            self.camera_info_callback, self.qos_sensor
        )
        self.create_subscription(
            Image, self.depth_topic,
            self.depth_callback, self.qos_sensor
        )
        self.create_subscription(
            CompressedImage, self.rgb_topic,
            self.rgb_callback, self.qos_sensor
        )

        # â–¶ FPS ê³„ì‚°ìš© ë³€ìˆ˜
        self.rgb_count = 0
        self.depth_count = 0

        # 1ì´ˆë§ˆë‹¤ FPS ì¶œë ¥ íƒ€ì´ë¨¸
        self.fps_timer = self.create_timer(1.0, self.print_fps)


        self.get_logger().info("TF Tree ì•ˆì •í™” ì‹œìž‘. 5ì´ˆ í›„ ë³€í™˜ ì‹œìž‘í•©ë‹ˆë‹¤.")
        self.start_timer = self.create_timer(5.0, self.start_transform)

    def start_transform(self):
        self.get_logger().info("TF Tree ì•ˆì •í™” ì™„ë£Œ. ë³€í™˜ + ì¶”ì  ì‹œìž‘í•©ë‹ˆë‹¤.")
        self.timer = self.create_timer(0.2, self.process_frame)
        self.start_timer.cancel()

    def camera_info_callback(self, msg):
        with self.lock:
            self.K = np.array(msg.k).reshape(3, 3)
            if not self.logged_intrinsics:
                self.get_logger().info(
                    f"Camera intrinsics received: "
                    f"fx={self.K[0,0]:.2f}, fy={self.K[1,1]:.2f}, "
                    f"cx={self.K[0,2]:.2f}, cy={self.K[1,2]:.2f}"
                )
                self.logged_intrinsics = True

    def depth_callback(self, msg):
        # (ì˜µì…˜) ì‹œê°„ ì²´í¬
        now = self.get_clock().now()
        now_sec = now.nanoseconds * 1e-9
        msg_sec = msg.header.stamp.sec + msg.header.stamp.nanosec * 1e-9
        dt = now_sec - msg_sec
        if dt > 0.5:
            self.get_logger().warn(
                f"Depth frame too old ({dt:.2f}s delay). Dropping frame."
            )
            return

        try:
            depth = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')

            # self.depth_count += 1  # FPS ì¸¡ì • ì¤‘ì´ë©´

            if depth is None or depth.size == 0:
                self.get_logger().error("Depth image is empty")
            else:
                if not self.logged_depth_shape:
                    self.get_logger().info(f"Depth image received: {depth.shape}")
                    self.logged_depth_shape = True

            with self.lock:
                self.depth_image = depth

        except Exception as e:
            self.get_logger().error(f"Depth CV bridge conversion failed: {e}")



    def rgb_callback(self, msg):
        # ðŸ”¹ ë¨¼ì € ì§€ì—°ì‹œê°„(dt) ê³„ì‚°
        now = self.get_clock().now()
        now_sec = now.nanoseconds * 1e-9
        msg_sec = msg.header.stamp.sec + msg.header.stamp.nanosec * 1e-9
        dt = now_sec - msg_sec

        # ë„ˆë¬´ ì˜¤ëž˜ëœ í”„ë ˆìž„ì´ë©´ ë²„ë¦¬ê¸° (ì˜ˆ: 0.5ì´ˆ ì´ìƒ)
        if dt > 0.5:
            self.get_logger().warn(
                f"RGB frame too old ({dt:.2f}s delay). Dropping frame."
            )
            return

        # ðŸ”¹ ì‹¤ì œ ë””ì½”ë”©ì€ ì—¬ê¸°ì„œ try/exceptë¡œ ê°ì‹¸ê¸°
        try:
            np_arr = np.frombuffer(msg.data, np.uint8)
            rgb = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)

            # FPS ì¹´ìš´íŠ¸ ì“°ê³  ìžˆìœ¼ë©´ ì—¬ê¸°ì„œ += 1
            # self.rgb_count += 1

            if rgb is None or rgb.size == 0:
                self.get_logger().error("Decoded RGB image is empty")
            else:
                if not self.logged_rgb_shape:
                    self.get_logger().info(f"RGB image decoded: {rgb.shape}")
                    self.logged_rgb_shape = True

            with self.lock:
                self.rgb_image = rgb

        except Exception as e:
            self.get_logger().error(f"Compressed RGB decode failed: {e}")


    def print_fps(self):
        self.get_logger().info(
            f"RGB FPS: {self.rgb_count}   |   Depth FPS: {self.depth_count}"
        )
        self.rgb_count = 0
        self.depth_count = 0



    def process_frame(self):
        if self.yolo_running:
            return

        with self.lock:
            rgb = self.rgb_image.copy() if self.rgb_image is not None else None
            depth = self.depth_image.copy() if self.depth_image is not None else None

        if rgb is None:
            return

        self.yolo_running = True
        now = self.get_clock().now()

        try:
            rgb_display = rgb.copy()
            boxes = self.run_yolo(rgb_display)

            target_found = False
            target_cx = None
            target_cy = None
            target_dist = None

            # ðŸ”¹ confidence ê¸°ì¤€ê°’
                        # ðŸ”¹ confidence ê¸°ì¤€ê°’
            MIN_CONF = 0.9

            best_box = None
            best_conf = 0.0  # ìµœê³  conf ì°¾ê¸°ìš©

            # 1) target_class ì¤‘ì—ì„œ conf ê°€ìž¥ ë†’ì€ ë°•ìŠ¤ ì°¾ê¸°
            for (x1, y1, x2, y2, name, conf) in boxes:
                if name == self.target_class and conf > best_conf:
                    best_conf = conf
                    best_box = (x1, y1, x2, y2, name, conf)

            # 2) best_boxë§Œ ì‹œê°í™” (ì›í•˜ë©´ MIN_CONF ì¡°ê±´ë„ ê°™ì´)
            if best_box is not None and best_conf >= MIN_CONF:
                x1, y1, x2, y2, name, conf = best_box
                cv2.rectangle(rgb_display, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(
                    rgb_display,
                    f"{name} {conf:.2f}",
                    (x1, max(0, y1 - 5)),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.6,
                    (0, 255, 0),
                    2
                )


            # rqtìš© YOLO ì´ë¯¸ì§€ í¼ë¸”ë¦¬ì‹œ
            img_msg = self.bridge.cv2_to_imgmsg(rgb_display, encoding='bgr8')
            img_msg.header.stamp = now.to_msg()
            img_msg.header.frame_id = 'oakd_rgb_frame'
            self.yolo_image_pub.publish(img_msg)

            # ðŸ”¹ car ê±°ë¦¬ ê³„ì‚° (conf â‰¥ 0.9 ì¸ ê²½ìš°ì—ë§Œ ì‚¬ìš©)
            if best_box is not None and best_conf >= MIN_CONF and depth is not None:
                x1, y1, x2, y2, name, conf = best_box
                cx = int((x1 + x2) / 2)
                # cy = int((y1 + y2) / 2)
                cy = int(y2 - (y2 - y1) * 0.05)


                if 0 <= cy < depth.shape[0] and 0 <= cx < depth.shape[1]:
                    z = float(depth[cy, cx]) / 1000.0
                    if 0.2 < z < 5.0:
                        target_found = True
                        target_cx = cx
                        target_cy = cy
                        target_dist = z
            else:
                # best_boxëŠ” ìžˆì—ˆëŠ”ë° confê°€ ë„ˆë¬´ ë‚®ì„ ë•Œ ë¡œê·¸ ì°ê³  ë¬´ì‹œí•˜ê³  ì‹¶ìœ¼ë©´:
                if best_box is not None and best_conf < MIN_CONF:
                    self.get_logger().debug(
                        f"Detected '{self.target_class}' but conf={best_conf:.2f} < {MIN_CONF}"
                    )

            if target_found:
                self.last_detection_time = now
                self.state = "TRACKING"
                self.search_start_time = None
                self.track_target(target_cx, target_cy, target_dist, rgb.shape)
            else:
                if self.last_detection_time is None:
                    self.state = "IDLE"
                    self.stop_robot()
                else:
                    elapsed = (now - self.last_detection_time).nanoseconds * 1e-9
                    if elapsed < self.lost_timeout:
                        self.state = "TRACKING"
                        self.stop_robot()
                    else:
                        if self.state != "SEARCHING":
                            self.state = "SEARCHING"
                            self.search_start_time = now
                            self.get_logger().info(
                                f"Target '{self.target_class}' lost. Start searching (rotate 360 deg)."
                            )
                        self.search_for_target(now)
        except Exception as e:
            self.get_logger().warn(f"Frame processing (YOLO/Publish/Control) error: {e}")
        finally:
            self.yolo_running = False


    def track_target(self, cx, cy, dist, image_shape):
        """carë¥¼ ì¼ì • ê±°ë¦¬ ë‘ê³  ë”°ë¼ê°€ëŠ” ì œì–´."""
        height, width, _ = image_shape

        # ì´ë¯¸ì§€ ì¤‘ì‹¬ ëŒ€ë¹„ x ë°©í–¥ ì˜¤ì°¨
        center_x = width / 2.0
        error_x = (cx - center_x) / center_x  # -1 ~ +1 ì •ë„ (ì •ê·œí™”ëœ ê°’)

        # ê±°ë¦¬ ì˜¤ì°¨ (ì•ž/ë’¤)
        dist_error = dist - self.follow_distance  # ë©€ë©´ +, ê°€ê¹Œìš°ë©´ -

        # ðŸ”¹ ê±°ë¦¬ ë°ë“œì¡´: ëª©í‘œ ê±°ë¦¬ Â± dist_deadband ì´ë‚´ë©´ ì „ì§„ ì•ˆ í•¨
        if abs(dist_error) < self.dist_deadband:
            dist_error = 0.0

        # ðŸ”¹ ê°ë„ ë°ë“œì¡´: ê±°ì˜ ì¤‘ì•™(Â±angle_deadband)ì´ë©´ íšŒì „ ì•ˆ í•¨
        if abs(error_x) < self.angle_deadband:
            error_x = 0.0

        # ì„ ì†ë„
        linear_x = self.k_v * dist_error
        # ë„ˆë¬´ ê°€ê¹Œìš´ë° dist_error<0 ë¼ê³  í•´ì„œ ë’¤ë¡œ ê°€ì§€ ì•Šê²Œ (ì›í•˜ë©´ ë’¤ë¡œë„ ê°€ê²Œ í’€ì–´ë„ ë¨)
        if dist < self.follow_distance and dist_error <= 0:
            linear_x = 0.0

        # ê°ì†ë„ (ì¢Œìš° ì •ë ¬)
        angular_z = - self.k_w * error_x

        # saturate
        linear_x = max(min(linear_x, self.max_linear_speed), -self.max_linear_speed)
        angular_z = max(min(angular_z, self.max_angular_speed), -self.max_angular_speed)

        # ðŸ”¹ ê±°ë¦¬Â·ê°ë„ ë‘˜ ë‹¤ ê±°ì˜ ë§žìœ¼ë©´ ì™„ì „ ì •ì§€ (LOG ì°ì–´ë´ë„ ì¢‹ìŒ)
        if linear_x == 0.0 and angular_z == 0.0:
            # self.get_logger().info("Target aligned & within distance. Holding pose.")
            self.stop_robot()
            return

        twist = Twist()
        twist.linear.x = float(linear_x)
        twist.angular.z = float(angular_z)
        self.cmd_vel_pub.publish(twist)


    def search_for_target(self, now):
        if self.search_start_time is None:
            self.search_start_time = now

        elapsed = (now - self.search_start_time).nanoseconds * 1e-9

        if elapsed < self.search_duration:
            twist = Twist()
            twist.linear.x = 0.0
            twist.angular.z = float(self.search_angular_speed)
            self.cmd_vel_pub.publish(twist)
        else:
            self.get_logger().info(
                f"Search finished. Target '{self.target_class}' not found. Go to IDLE."
            )
            self.state = "IDLE"
            self.stop_robot()
            self.last_detection_time = None
            self.search_start_time = None

    def stop_robot(self):
        twist = Twist()
        twist.linear.x = 0.0
        twist.angular.z = 0.0
        self.cmd_vel_pub.publish(twist)

    def run_yolo(self, rgb_image):
        results = self.yolo(rgb_image)
        boxes = []
        for r in results:
            for box in r.boxes:
                x1, y1, x2, y2 = [int(v) for v in box.xyxy[0]]
                conf = float(box.conf[0])
                cls_id = int(box.cls[0])
                cls_name = self.yolo.names[cls_id]
                boxes.append((x1, y1, x2, y2, cls_name, conf))
        return boxes


def main():
    rclpy.init()
    node = DepthToMap()
    executor = MultiThreadedExecutor()
    executor.add_node(node)
    try:
        executor.spin()
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        rclpy.shutdown()


if __name__ == '__main__':
    main()